# -*- coding: utf-8 -*-
"""Final of Gradio Webapp MobileNetv3large(98_test)_Training_Integrated_Dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x4DRTyEkSMVa2gxzpTCfldt8o1pXzXJu
"""

pip install gradio

import gradio as gr
from PIL import Image
from keras.preprocessing.image import array_to_img

import numpy as np
import os
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from keras.models import Model
from keras.layers import Input, Dense, Flatten, Dropout
from keras.optimizers import Adam
from keras.applications import MobileNetV3Large
from keras.preprocessing.image import img_to_array, load_img
from sklearn.model_selection import train_test_split
from keras.callbacks import ModelCheckpoint
from sklearn.preprocessing import LabelEncoder
from keras.models import load_model

from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

data = pd.read_csv("/content/drive/MyDrive/Autism_CSV_Files/Integrated_Dataset_Processed_Training_Final.csv")

data.head()

def preprocess_image(image_path):
    # Load the image from the drive link
    img = load_img(image_path, target_size=(224, 224))
    img_array = img_to_array(img)
    img_array = img_array / 255.0  # Normalize pixel values to [0, 1]
    return img_array

label_encoder = LabelEncoder()
data['ASD'] = label_encoder.fit_transform(data['ASD'])

data.tail()

# Preprocess images and save preprocessed data
preprocessed_image_path = '/content/drive/MyDrive/Training_Autism_Model.npy'
if os.path.exists(preprocessed_image_path):
    image_data = np.load(preprocessed_image_path)
else:
    image_data = np.array([preprocess_image(image_path) for image_path in data['image_path']])
    np.save(preprocessed_image_path, image_data)

# Extract numerical features
numerical_features = data[['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score']].values

# Split the data into train and test sets
X_img_train, X_img_test, X_num_train, X_num_test, y_train, y_test = train_test_split(image_data, numerical_features, data['ASD'], test_size=0.2, random_state=42)

# Define base model
base_model = MobileNetV3Large(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the base model
base_model.trainable = False

# Functional API for model building
input_img = Input(shape=(224, 224, 3), name='image_input')
x = base_model(input_img, training=False)
x = Flatten()(x)
input_num = Input(shape=(10,), name='numerical_input')
concatenated = tf.keras.layers.concatenate([x, input_num])
x = Dense(128, activation='relu')(concatenated)
x = Dropout(0.5)(x)
output = Dense(1, activation='sigmoid', name='output')(x)

# Define the model
model = Model(inputs=[input_img, input_num], outputs=output)

model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])

checkpoint = ModelCheckpoint('/content/drive/MyDrive/Training_Autism_Model/MobileNetV3Large.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)

history = model.fit([X_img_train, X_num_train], y_train, batch_size=32, epochs=10, validation_split=0.2, callbacks=[checkpoint])

# Load the model
model = load_model('/content/drive/MyDrive/Training_Autism_Model/MobileNetV3Large.h5')

# Now you can use loaded_model for predictions or further training

history = model.fit([X_img_train, X_num_train], y_train,
                    batch_size=32, epochs=100,
                    initial_epoch=10,
                    validation_split=0.2,  # 20% of training data will be used for validation
                    callbacks=[checkpoint])

history = model.fit([X_img_train, X_num_train], y_train,
                    batch_size=32, epochs=130,
                    initial_epoch=100,
                    validation_split=0.2,  # 20% of training data will be used for validation
                    callbacks=[checkpoint])

history = model.fit([X_img_train, X_num_train], y_train,
                    batch_size=32, epochs=150,
                    initial_epoch=130,
                    validation_split=0.2,  # 20% of training data will be used for validation
                    callbacks=[checkpoint])

history = model.fit([X_img_train, X_num_train], y_train,
                    batch_size=32, epochs=200,
                    initial_epoch=150,
                    validation_split=0.2,  # 20% of training data will be used for validation
                    callbacks=[checkpoint])

# Evaluate the model
loss, accuracy = model.evaluate([X_img_test, X_num_test], y_test)
print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')

from sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score


# Get the predicted labels for the test data
y_pred = model.predict([X_img_test, X_num_test])

# Convert the predicted probabilities to binary labels (0 or 1)
y_pred_binary = (y_pred > 0.5).astype(int)

# Compute precision, recall, and F1-score
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
f1 = f1_score(y_test, y_pred_binary)


# Compute accuracy
accuracy = accuracy_score(y_test, y_pred_binary)

# Print the results
print("Accuracy:", accuracy)
# Print the results
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Compute the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred_binary)

# Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

plt.savefig('confusion_matrix.png')

import matplotlib.pyplot as plt



# Plot train vs test accuracy
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Test Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Train vs Test Accuracy')
plt.legend()
plt.savefig('train_test_accuracy.png')
plt.show()

# Plot train vs test AUC
plt.plot(history.history['auc'], label='Train AUC')
plt.plot(history.history['val_auc'], label='Test AUC')
plt.xlabel('Epoch')
plt.ylabel('AUC')
plt.title('Train vs Test AUC')
plt.legend()
plt.savefig('train_test_auc.png')
plt.show()

# Similarly, plot and save other metrics like precision, recall, etc.

# Define the question prompts
questions = [
    "S/he often notices small sounds when others do not",
    "S/he usually concentrates more on the whole picture, rather than the small details",
    "In a social group, s/he can easily keep track of several different people’s conversations",
    "S/he finds it easy to go back and forth between different activities",
    "S/he doesn’t know how to keep a conversation going with his/her peers",
    "S/he is good at social chit-chat",
    "When s/he is read a story, s/he finds it difficult to work out the character’s intentions or feelings",
    "When s/he was in preschool, s/he used to enjoy playing games involving pretending with other children",
    "S/he finds it easy to work out what someone is thinking or feeling just by looking at their face",
    "S/he finds it hard to make new friends"
]

def predict_autism(image_path, A1_Score, A2_Score, A3_Score, A4_Score, A5_Score, A6_Score, A7_Score, A8_Score, A9_Score, A10_Score):
    # Preprocess the image
    img = load_img(image_path, target_size=(224, 224))
    img_array = img_to_array(img)
    img_array = img_array / 255.0  # Normalize pixel values to [0, 1]

    # Convert the numerical features to a numpy array
    x = np.array([A1_Score, A2_Score, A3_Score, A4_Score, A5_Score, A6_Score, A7_Score, A8_Score, A9_Score, A10_Score])

    # Predict using the model
    prediction = model.predict([img_array.reshape(1, 224, 224, 3), x.reshape(1, -1)])
    return prediction

import random

# Define the image path
image_path = "/content/drive/MyDrive/consolidated/autistic/0002.jpg"

# Define the scores randomly
A1_Score = 0
A2_Score = 0
A3_Score = 0
A4_Score = 1
A5_Score = 0
A6_Score = 1
A7_Score = 1
A8_Score = 0
A9_Score = 1
A10_Score = 0
prediction = predict_autism(image_path, A1_Score, A2_Score, A3_Score, A4_Score, A5_Score, A6_Score, A7_Score, A8_Score, A9_Score, A10_Score)
# Convert the predicted probability to a binary prediction
if prediction >= 0.5:
    binary_prediction = 1
    prediction_text = "Probable ASD Patient"
else:
    binary_prediction = 0
    prediction_text = "Not Probable ASD Patient"

print(binary_prediction)
print(prediction_text)

def predict_autism_gradio(img_numpy_array, A1_Score, A2_Score, A3_Score, A4_Score, A5_Score, A6_Score, A7_Score, A8_Score, A9_Score, A10_Score):
    # Preprocess the image
    img = array_to_img(img_numpy_array)
    img = img.resize((224,224))
    img_array = img_to_array(img)


    if not isinstance(img_numpy_array, np.ndarray):
        raise TypeError("img_numpy_array must  be a numpy array")

    img_array = img_array / 255.0  # Normalize pixel values to [0, 1]

    # Convert the numerical features to a numpy array
    x = np.array([A1_Score, A2_Score, A3_Score, A4_Score, A5_Score, A6_Score, A7_Score, A8_Score, A9_Score, A10_Score])

    # Predict using the model
    prediction = model.predict([img_array.reshape(1, 224, 224, 3), x.reshape(1, -1)])
    if prediction >= 0.5:
      binary_prediction = 1
      prediction_text = "ASD: Positive"
    else:
      binary_prediction = 0
      prediction_text = "ASD: Negative"

    return prediction_text

outputs = gr.components.Textbox()

app = gr.Interface(fn=predict_autism_gradio,
                   inputs=["image",
                           "number", "number", "number", "number", "number",
                           "number", "number", "number", "number", "number"],
                   outputs=outputs,
                   description="Predict if autism is present based on image and AQ-10 scores")

app.launch(share=True)

import gradio as gr

# Define the question prompts
questions = [
    "1. S/he often notices small sounds when others do not. (Enter 1 if you Definitely/Slightly Agree with the statement and Enter 0 if you Definitely/Slightly Disagree with the statement.)",
    "2. S/he usually concentrates more on the whole picture, rather than the small details (Enter 0 if you Definitely/Slightly Agree with the statement and Enter 1 if you Definitely/Slightly Disagree with the statement.)",
    "3. In a social group, s/he can easily keep track of several different people’s conversations (Enter 0 if you Definitely/Slightly Agree with the statement and Enter 1 if you Definitely/Slightly Disagree with the statement.)",
    "4. S/he finds it easy to go back and forth between different activities (Enter 0 if you Definitely/Slightly Agree with the statement and Enter 1 if you Definitely/Slightly Disagree with the statement.)",
    "5. S/he doesn’t know how to keep a conversation going with his/her peers (Enter 1 if you Definitely/Slightly Agree with the statement and Enter 0 if you Definitely/Slightly Disagree with the statement.)",
    "6. S/he is good at social chit-chat (Enter 0 if you Definitely/Slightly Agree with the statement and Enter 1 if you Definitely/Slightly Disagree with the statement.)",
    "7. When s/he is read a story, s/he finds it difficult to work out the character’s intentions or feelings (Enter 1 if you Definitely/Slightly Agree with the statement and Enter 0 if you Definitely/Slightly Disagree with the statement.)",
    "8. When s/he was in preschool, s/he used to enjoy playing games involving pretending with other children (Enter 0 if you Definitely/Slightly Agree with the statement and Enter 1 if you Definitely/Slightly Disagree with the statement.)",
    "9. S/he finds it easy to work out what someone is thinking or feeling just by looking at their face (Enter 0 if you Definitely/Slightly Agree with the statement and Enter 1 if you Definitely/Slightly Disagree with the statement.)",
    "10. S/he finds it hard to make new friends (Enter 1 if you Definitely/Slightly Agree with the statement and Enter 0 if you Definitely/Slightly Disagree with the statement.)"
]


# Define the input components
inputs = [gr.components.Image(label="Image")]  # Assuming you have an image input
for i, question in enumerate(questions):
    inputs.append(gr.components.Number(label=question, minimum=0, maximum=10))

# Define the output components
outputs = gr.components.Label(label="Prediction")

# Define the Gradio interface
demo = gr.Interface(fn=predict_autism_gradio,
                   inputs=inputs,
                   outputs=outputs,
                   description="Predict if autism is present based on image and AQ-10 scores")

# Run the Gradio interface
demo.launch()

